{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e44db66",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier as XGB\n",
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.model_selection import train_test_split  # 随机划分数据集\n",
    "import matplotlib.pyplot as plt\n",
    "from warnings import simplefilter\n",
    "\n",
    "simplefilter(action='ignore') #忽略警告"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ba8d77f",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xb8 in position 1: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32mC:\\temp/ipykernel_3744/1255660058.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#读取数据\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model_feature.csv'\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 读入csv文件中的特征\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"初始数据如下：\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\张思源\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\张思源\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\张思源\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\张思源\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\张思源\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             )\n\u001b[0;32m   1039\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\张思源\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"dtype\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_dtype_objs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"dtype\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\张思源\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\users\\张思源\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\users\\张思源\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\users\\张思源\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xb8 in position 1: invalid start byte"
     ]
    }
   ],
   "source": [
    "#读取数据\n",
    "\n",
    "df = pd.read_csv('model_feature.csv')  # 读入csv文件中的特征\n",
    "\n",
    "print(\"初始数据如下：\")\n",
    "pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dd9575",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#分离特征及标签\n",
    "\n",
    "X = df.drop('fatigue_result', axis=1)  # 移除fatigue_result列,其它列都是特征\n",
    "Y = df['fatigue_result']  # 提取出标签页\n",
    "\n",
    "print(\"提取出标签后的特征如下：\")\n",
    "pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a49749",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"标签如下：\")\n",
    "pd.DataFrame(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b204d16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#对字符型特征进行特征编码（age_level和is_fatigue）\n",
    "\n",
    "le = LabelEncoder()# 进行特征编码\n",
    "X['age_level'] = le.fit_transform(X['age_level'])\n",
    "X['is_fatigue'] = le.fit_transform(X['is_fatigue'])\n",
    "\n",
    "print(\"特征编码后的数据如下：\")\n",
    "pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f53485",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2,svd_solver=\"full\")\n",
    "#加载PCA算法，设置降维后主成分数目为2\n",
    " \n",
    "pca = pca.fit(X) #拟合模型\n",
    "X_pca=pca.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952e4c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#只保留两个特征时的图像\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(X_pca[Y==0,0],X_pca[Y==0,1],c=\"green\",label=\"0\")\n",
    "plt.scatter(X_pca[Y==1,0],X_pca[Y==1,1],c=\"orange\",label=\"1\")\n",
    "plt.scatter(X_pca[Y==2,0],X_pca[Y==2,1],c=\"red\",label=\"2\")\n",
    "plt.legend()\n",
    "plt.title(\"PCA of Data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4602f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_  #查看降维后每个新特征向量上所带的信息量大小（可理解为方差大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b2179b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_  #查看降维后每个新特征向量所占原始数据信息量的百分比（可理解为方差贡献率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4baccb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_.sum() #信息保留量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12085cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA中，选择合适的n_components参数的过程\n",
    "\n",
    "pca_line=PCA().fit(X)\n",
    "plt.plot([1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24],np.cumsum(pca_line.explained_variance_ratio_))\n",
    "plt.xticks([1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24])\n",
    "plt.xlabel(\"number of components after dimension reduction\")\n",
    "plt.ylabel(\"cumulative explained variance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86bd351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 参数优化过程\n",
    "# model_range=range(1,20)\n",
    "# model_score = []\n",
    "# for i in model_range:\n",
    "#     rf = RF(n_estimators=130,random_state=i)\n",
    "#     # loss=-cross_val_score(rf,x_test,y_test,cv=5)\n",
    "#     # model_score.append(loss.mean())\n",
    "#     scores = cross_val_score(rf, X, Y, cv=5)\n",
    "#     model_score.append(scores.mean())\n",
    "# plt.plot(model_range,model_score,label = 'test_score')\n",
    "# plt.xlabel('random_state')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "#没有进行PCA时的模型表现\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y,random_state = 1,test_size=0.20)\n",
    "\n",
    "'''随机森林'''\n",
    "rf = RF(random_state=50,n_estimators=130,max_depth=30)\n",
    "rf.fit(x_train, y_train)\n",
    "print(f'随机森林准确率为{rf.score(x_test, y_test)}')\n",
    "\n",
    "\n",
    "'''XGBoost'''\n",
    "xgb = XGB(random_state=50,n_estimators=10,eval_metric = 'logloss')\n",
    "xgb.fit(x_train,y_train)\n",
    "print(f'XGBoost准确率为{rf.score(x_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d61863",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#寻找最佳降维数据的过程\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "ans1 = []\n",
    "ans2 = []\n",
    "ans1_pca = []\n",
    "ans2_pca = []\n",
    "\n",
    "\n",
    "#计算PCA前的AUC\n",
    "recall_rf = []\n",
    "recall_xgb = []\n",
    "FPR_rf = []\n",
    "FPR_xgb = []\n",
    "y_true = y_test\n",
    "prob_rf = rf.predict_proba(x_test)\n",
    "prob_xgb = xgb.predict_proba(x_test)\n",
    "probrange_rf = np.linspace(prob_rf[:, 1].min(), prob_rf[:, 1].max(), 50)\n",
    "probrange_xgb = np.linspace(prob_xgb[:, 1].min(), prob_xgb[:, 1].max(),50)\n",
    "for i in probrange_rf:\n",
    "    y_pre = []\n",
    "    for k in range(prob_rf.shape[0]):\n",
    "        if prob_rf[k, 1] > i:\n",
    "            y_pre.append(1)\n",
    "        else:\n",
    "            y_pre.append(0)\n",
    "    C = confusion_matrix(y_true, y_pre)\n",
    "    recall_rf.append(C[0, 0] / C[0, :].sum())\n",
    "    FPR_rf.append(C[1, 0] / C[1, :].sum())\n",
    "for i in probrange_xgb:\n",
    "    y_pre = []\n",
    "    for k in range(prob_xgb.shape[0]):\n",
    "        if prob_xgb[k, 1] > i:\n",
    "            y_pre.append(1)\n",
    "        else:\n",
    "            y_pre.append(0)\n",
    "    C = confusion_matrix(y_true, y_pre)\n",
    "    recall_xgb.append(C[0, 0] / C[0, :].sum())\n",
    "    FPR_xgb.append(C[1, 0] / C[1, :].sum())\n",
    "    \n",
    "'''进行特征选择'''\n",
    "X = X.drop(['is_fatigue','age_level','accumulate_driving_after_maxSpare','accumulate_times_before24',\n",
    "                            'accumulate_times_after_maxSpare','alarm_face_before_5min'],axis=1)\n",
    "    \n",
    "#循环遍历不同的降维数据对结果的影响\n",
    "for i in  range(1,18):\n",
    "    \n",
    "    #PCA前\n",
    "    ans1.append(round(auc(FPR_rf, recall_rf), 3))\n",
    "    ans2.append(round(auc(FPR_xgb, recall_xgb), 3))\n",
    "    \n",
    "    \n",
    "    #进行PCA\n",
    "    n_pca = PCA(n_components=i,svd_solver=\"full\")    #加载PCA算法，设置降维后主成分数目为i\n",
    "    n_pca = n_pca.fit(X) #拟合模型\n",
    "    X_pca=n_pca.transform(X)\n",
    "    x_train_pca, x_test_pca, y_train_pca, y_test_pca = train_test_split(X_pca, Y,random_state = 1, test_size=0.20)\n",
    "   \n",
    "\n",
    "    rf_pca = RF(random_state=50,n_estimators=130,max_depth=30)\n",
    "    rf_pca.fit(x_train_pca, y_train_pca)\n",
    "    \n",
    "    xgb_pca = XGB(random_state=50,n_estimators=10,eval_metric = 'logloss')\n",
    "    xgb_pca.fit(x_train_pca,y_train_pca)\n",
    "\n",
    "    recall_rf_pca = []\n",
    "    recall_xgb_pca = []\n",
    "    FPR_rf_pca = []\n",
    "    FPR_xgb_pca = []\n",
    "    y_true = y_test_pca\n",
    "    prob_rf_pca = rf_pca.predict_proba(x_test_pca)\n",
    "    prob_xgb_pca = xgb_pca.predict_proba(x_test_pca)\n",
    "    probrange_rf_pca = np.linspace(prob_rf_pca[:, 1].min(), prob_rf_pca[:, 1].max(), 50)\n",
    "    probrange_xgb_pca = np.linspace(prob_xgb_pca[:, 1].min(), prob_xgb_pca[:, 1].max(),50)\n",
    "    for i in probrange_rf_pca:\n",
    "        y_pre = []\n",
    "        for k in range(prob_rf_pca.shape[0]):\n",
    "            if prob_rf_pca[k, 1] > i:\n",
    "                y_pre.append(1)\n",
    "            else:\n",
    "                y_pre.append(0)\n",
    "        C = confusion_matrix(y_true, y_pre)\n",
    "        recall_rf_pca.append(C[0, 0] / C[0, :].sum())\n",
    "        FPR_rf_pca.append(C[1, 0] / C[1, :].sum())\n",
    "    for i in probrange_xgb_pca:\n",
    "        y_pre = []\n",
    "        for k in range(prob_xgb_pca.shape[0]):\n",
    "            if prob_xgb_pca[k, 1] > i:\n",
    "                y_pre.append(1)\n",
    "            else:\n",
    "                y_pre.append(0)\n",
    "        C = confusion_matrix(y_true, y_pre)\n",
    "        recall_xgb_pca.append(C[0, 0] / C[0, :].sum())\n",
    "        FPR_xgb_pca.append(C[1, 0] / C[1, :].sum())\n",
    "    \n",
    "    ans1_pca.append(round(auc(FPR_rf_pca, recall_rf_pca), 6)) #随机森林\n",
    "    ans2_pca.append(round(auc(FPR_xgb_pca, recall_xgb_pca), 6)) #XGBoost\n",
    "    \n",
    "plt.figure()\n",
    "plt.xlabel(\"number of components after dimension reduction\")\n",
    "plt.ylabel(\"AUC of model\")\n",
    "plt.plot(range(1,24,1),ans1,c='darkblue',label = 'RF')\n",
    "plt.plot(range(1,24,1),ans1_pca,c='lightblue',label = 'RF PCA')\n",
    "plt.plot(range(1,24,1),ans2,c='red',label = 'XGB')\n",
    "plt.plot(range(1,24,1),ans2_pca,c='pink',label='XGB PCA')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a52c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#用上段代码测出的最佳降维参数进行PCA\n",
    "\n",
    "'''随机森林'''\n",
    "n_pca = PCA(n_components=16,svd_solver=\"full\")    #加载PCA算法，设置降维后主成分数目为16\n",
    "n_pca = n_pca.fit(X) #拟合模型\n",
    "X_pca1=n_pca.transform(X)\n",
    "x_train_pca1, x_test_pca1, y_train_pca1, y_test_pca1 = train_test_split(X_pca1, Y,random_state = 1, test_size=0.20)\n",
    "   \n",
    "rf_pca = RF(random_state=50,n_estimators=130,max_depth=30)\n",
    "rf_pca.fit(x_train_pca1, y_train_pca1)\n",
    "\n",
    "\n",
    "'''XGBoost'''\n",
    "n_pca = PCA(n_components=18,svd_solver=\"full\")    #加载PCA算法，设置降维后主成分数目为18\n",
    "n_pca = n_pca.fit(X) #拟合模型\n",
    "X_pca2=n_pca.transform(X)\n",
    "x_train_pca2, x_test_pca2, y_train_pca2, y_test_pca2 = train_test_split(X_pca2, Y,random_state = 1, test_size=0.20)\n",
    "\n",
    "xgb_pca = XGB(random_state=50,n_estimators=10,eval_metric = 'logloss')\n",
    "xgb_pca.fit(x_train_pca2,y_train_pca2)\n",
    "\n",
    "pd.DataFrame(X_pca1) #随机森林降维后的特征数据\n",
    "pd.DataFrame(X_pca2) #XGBoost降维后的特征数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9a79af",
   "metadata": {},
   "outputs": [],
   "source": [
    " from sklearn.metrics import confusion_matrix\n",
    "\n",
    "plt.figure(figsize=(12, 8.4))\n",
    "plt.xlabel('false positive rate', fontsize=16)\n",
    "plt.ylabel('true positive rate', fontsize=16)\n",
    "plt.plot([0, 1], [0, 1], c='black', linestyle='--')\n",
    "\n",
    "#pca前\n",
    "recall_rf = []\n",
    "recall_xgb = []\n",
    "FPR_rf = []\n",
    "FPR_xgb = []\n",
    "y_true = y_test\n",
    "prob_rf = rf.predict_proba(x_test)\n",
    "prob_xgb = xgb.predict_proba(x_test)\n",
    "probrange_rf = np.linspace(prob_rf[:, 1].min(), prob_rf[:, 1].max(), 50)\n",
    "probrange_xgb = np.linspace(prob_xgb[:, 1].min(), prob_xgb[:, 1].max(),50)\n",
    "for i in probrange_rf:\n",
    "    y_pre = []\n",
    "    for k in range(prob_rf.shape[0]):\n",
    "        if prob_rf[k, 1] > i:\n",
    "            y_pre.append(1)\n",
    "        else:\n",
    "            y_pre.append(0)\n",
    "    C = confusion_matrix(y_true, y_pre)\n",
    "    recall_rf.append(C[0, 0] / C[0, :].sum())\n",
    "    FPR_rf.append(C[1, 0] / C[1, :].sum())\n",
    "for i in probrange_xgb:\n",
    "    y_pre = []\n",
    "    for k in range(prob_xgb.shape[0]):\n",
    "        if prob_xgb[k, 1] > i:\n",
    "            y_pre.append(1)\n",
    "        else:\n",
    "            y_pre.append(0)\n",
    "    C = confusion_matrix(y_true, y_pre)\n",
    "    recall_xgb.append(C[0, 0] / C[0, :].sum())\n",
    "    FPR_xgb.append(C[1, 0] / C[1, :].sum())\n",
    "area_rf = \"AUC area of RF is \" + str(round(auc(FPR_rf, recall_rf), 3))\n",
    "area_xgb = \"AUC area of XGB is \" + str(round(auc(FPR_xgb, recall_xgb), 3))\n",
    "plt.plot(FPR_rf, recall_rf, c='darkblue',label=area_rf)\n",
    "plt.plot(FPR_xgb, recall_xgb, c='red',label=area_xgb)\n",
    "\n",
    "\n",
    "#pca后\n",
    "recall_rf_pca = []\n",
    "recall_xgb_pca = []\n",
    "FPR_rf_pca = []\n",
    "FPR_xgb_pca = []\n",
    "y_true = y_test_pca\n",
    "prob_rf_pca = rf_pca.predict_proba(x_test_pca1)\n",
    "prob_xgb_pca = xgb_pca.predict_proba(x_test_pca2)\n",
    "probrange_rf_pca = np.linspace(prob_rf_pca[:, 1].min(), prob_rf_pca[:, 1].max(), 50)\n",
    "probrange_xgb_pca = np.linspace(prob_xgb_pca[:, 1].min(), prob_xgb_pca[:, 1].max(),50)\n",
    "for i in probrange_rf_pca:\n",
    "    y_pre = []\n",
    "    for k in range(prob_rf_pca.shape[0]):\n",
    "        if prob_rf_pca[k, 1] > i:\n",
    "            y_pre.append(1)\n",
    "        else:\n",
    "            y_pre.append(0)\n",
    "    C = confusion_matrix(y_true, y_pre)\n",
    "    recall_rf_pca.append(C[0, 0] / C[0, :].sum())\n",
    "    FPR_rf_pca.append(C[1, 0] / C[1, :].sum())\n",
    "for i in probrange_xgb_pca:\n",
    "    y_pre = []\n",
    "    for k in range(prob_xgb_pca.shape[0]):\n",
    "        if prob_xgb_pca[k, 1] > i:\n",
    "            y_pre.append(1)\n",
    "        else:\n",
    "            y_pre.append(0)\n",
    "    C = confusion_matrix(y_true, y_pre)\n",
    "    recall_xgb_pca.append(C[0, 0] / C[0, :].sum())\n",
    "    FPR_xgb_pca.append(C[1, 0] / C[1, :].sum())\n",
    "area_rf_pca = \"(PCA) AUC area of RF is \" + str(round(auc(FPR_rf_pca, recall_rf_pca), 3))\n",
    "area_xgb_pca = \"(PCA) AUC area of XGB is \" + str(round(auc(FPR_xgb_pca, recall_xgb_pca), 3))\n",
    "plt.plot(FPR_rf_pca, recall_rf_pca, c='lightblue',label=area_rf_pca)\n",
    "plt.plot(FPR_xgb_pca, recall_xgb_pca, c='pink',label=area_xgb_pca)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14510d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型指标\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "#PCA前\n",
    "print(\"\\nPCA之前的指标\")\n",
    "#随机森林\n",
    "print('\\n随机森林')\n",
    "print(f'准确率为{rf.score(x_test, y_test)}')\n",
    "print(f'AUC面积为{round(auc(FPR_rf, recall_rf), 6)}')\n",
    "y_predict = rf.predict(x_test)\n",
    "print(f'宏F1为{f1_score(y_test, y_predict,average=\"macro\")}')\n",
    "print(f'微F1为{f1_score(y_test, y_predict,average=\"micro\")}')\n",
    "print(f'宏查准率为{precision_score(y_test, y_predict,average=\"macro\")}')\n",
    "print(f'微查准率为{precision_score(y_test, y_predict,average=\"micro\")}')\n",
    "print(f'宏查全率为{recall_score(y_test, y_predict,average=\"macro\")}')\n",
    "print(f'微查全率为{recall_score(y_test, y_predict,average=\"micro\")}')\n",
    "\n",
    "#XGBoost\n",
    "print('\\nXGBoost')\n",
    "print(f'准确率为{xgb.score(x_test, y_test)}')\n",
    "print(f'AUC面积为{round(auc(FPR_xgb, recall_xgb), 6)}')\n",
    "y_predict = xgb.predict(x_test)\n",
    "print(f'宏F1为{f1_score(y_test, y_predict,average=\"macro\")}')\n",
    "print(f'微F1为{f1_score(y_test, y_predict,average=\"micro\")}')\n",
    "print(f'宏查准率为{precision_score(y_test, y_predict,average=\"macro\")}')\n",
    "print(f'微查准率为{precision_score(y_test, y_predict,average=\"micro\")}')\n",
    "print(f'宏查全率为{recall_score(y_test, y_predict,average=\"macro\")}')\n",
    "print(f'微查全率为{recall_score(y_test, y_predict,average=\"micro\")}')\n",
    "\n",
    "\n",
    "#PCA后\n",
    "print(\"\\nPCA之后的指标\")\n",
    "#随机森林\n",
    "print('\\n随机森林')\n",
    "print(f'准确率为{rf_pca.score(x_test_pca1, y_test_pca1)}')\n",
    "print(f'AUC面积为{round(auc(FPR_rf_pca, recall_rf_pca), 6)}')\n",
    "y_predict = rf_pca.predict(x_test_pca1)\n",
    "print(f'宏F1为{f1_score(y_test_pca1, y_predict,average=\"macro\")}')\n",
    "print(f'微F1为{f1_score(y_test_pca1, y_predict,average=\"micro\")}')\n",
    "print(f'宏查准率为{precision_score(y_test_pca1, y_predict,average=\"macro\")}')\n",
    "print(f'微查准率为{precision_score(y_test_pca1, y_predict,average=\"micro\")}')\n",
    "print(f'宏查全率为{recall_score(y_test_pca1, y_predict,average=\"macro\")}')\n",
    "print(f'微查全率为{recall_score(y_test_pca1, y_predict,average=\"micro\")}')\n",
    "\n",
    "#XGBoost\n",
    "print('\\nXGBoost')\n",
    "print(f'准确率为{xgb_pca.score(x_test_pca2, y_test_pca2)}')\n",
    "print(f'AUC面积为{round(auc(FPR_xgb_pca, recall_xgb_pca), 6)}')\n",
    "y_predict = xgb_pca.predict(x_test_pca2)\n",
    "print(f'宏F1为{f1_score(y_test_pca2, y_predict,average=\"macro\")}')\n",
    "print(f'微F1为{f1_score(y_test_pca2, y_predict,average=\"micro\")}')\n",
    "print(f'宏查准率为{precision_score(y_test_pca2, y_predict,average=\"macro\")}')\n",
    "print(f'微查准率为{precision_score(y_test_pca2, y_predict,average=\"micro\")}')\n",
    "print(f'宏查全率为{recall_score(y_test_pca2, y_predict,average=\"macro\")}')\n",
    "print(f'微查全率为{recall_score(y_test_pca2, y_predict,average=\"micro\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c869e1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# pd.DataFrame(x_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
